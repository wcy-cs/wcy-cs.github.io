<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Face Restoration</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Spatial-Frequency Mutual Learning for Low-Light Face Restoration</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=L6mVzXkAAAAJ&hl=en" target="_blank">Chenyang Wang</a></sup>,
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=WNH2_rgAAAAJ&hl=en" target="_blank">Junjun Jiang</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=OepYczoAAAAJ&hl=zh-CN" target="_blank">Zhiwei Zhong</a></sup>,
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?user=AbOLE9QAAAAJ&hl=zh-CN" target="_blank">Kui Jiang</a></sup>,
                  <span class="author-block">
                    <a href="https://homepage.hit.edu.cn/xmliu?lang=en" target="_blank">Xianming Liu</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Faculty of Computing, Harbin Institute of Technology, China</span>
                
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
        Face restoration aims to recover high-quality face images from the low-quality ones. With the advent of deep learning, face restoration technique has achieved significant breakthroughs. However, human face captured at night or in dimly lit environments has become a common practice, accompanied low-light degradation which is ignored by the existing methods. Moreover, existing methods focus exclusively on recovering face images within the spatial domain, rarely exploring the possible solutions in the frequency domain that is important for computer vision. Methods only in spatial domain cannot simultaneously preserve both lightness and structure details. In frequency domain, the amplitude component contains lightness information while the phase component can characterize facial structure information, making Fourier transform naturally suited for this task. Thus, we propose a novel spatial-frequency mutual learning network for low-light face restoration. Given the complementarity between spatial and frequency domains and the intrinsic coupling of phase and amplitude, we propose a dual interactive coupling mechanism, including spatial-frequency and amplitude-phase interactions. Towards the former, we develop a bi-directional frequency-spatial interaction block to mutually amalgamate the complementary spatial and frequency information, enhancing the feature representation capability of the model. As for the latter, the amplitude-phase interaction block is built to achieve the collaboration between phase and amplitude (structure and lightness), performing better low-light face restoration. Extensive experiments validate the effectiveness of our method and demonstrate its superior performance over prior arts in recovering low-light face images, validating its potential in wide-range applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Motivation</h2>
          <div class="level-set has-text-justified">
            <p>
        We exchange the amplitude component of LL and NL, and then reconstruct the corresponding face images by inverse Fourier transform. In Fig. a, it can be seen that the light of the two faces exchanges following the swapping of amplitude although the reconstructed face has obvious artifacts. This phenomenon indicates the amplitude component represents the lightness of the face image. We also obverse that the exchanged faces has obvious artifacts, demonstrating that phase and amplitude are coupled and enhancing only one component would not yield satisfactory results. Moreover, Fig. b illustrates the face images reconstructed by the amplitude component and phase component, respectively. Obviously, the phase representation reveals clear global facial structure information that can boost face restoration. That is to say, the amplitude component represents lightness information and the phase component can well characterize the facial structure information, making the Fourier transform a perfect fit for low-light face restoration task. <br><br>
            </p>
          </div>
          <img src="static/images/motivation.png" alt="Normal and Anomalous Representations" class="center-image"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Method Overview</h2>
          <div class="level-set has-text-justified">
            <p>
        We develop a spatial-frequency mutual network (SFMNet++) for low-light face restoration, exploring the incorporation between spatial and frequency domains.  Given the complementarity between spatial and frequency domains, and the intrinsic coupling of phase and amplitude, we propose a dual interactive coupling mechanism that includes spatial-frequency interactions and interactions between amplitude and phase (structure and brightness) to achieve better low-light face restoration.  <br><br>
            </p>
          </div>
          <img src="static/images/method.png" alt="Normal and Anomalous Representations" class="center-image"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Quantitative Comparison</h2>
          <div class="level-set has-text-justified">
            <p>
        Comparison methods: prior-guided method FSRNet, convolution neural network-based methods SPARNet, and recently-proposed transformer-based methods SCTANet and FaceFormer , a low-light face super-resolution method IEFSR, and our previous conference version SFMNet.  <br><br>
            </p>
          </div>
          <img src="static/images/quantitative.png" alt="Normal and Anomalous Representations" class="center-image"/>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero is-light">
  <div class="hero-body">
    <h2 class="title is-3">Qualitative Comparison</h2>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/sr.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br>
          Low-Light Face Super-resolution Comparison
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/denoising.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br>
          Low-Light Face Denoising Comparison
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/artifact.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br>
         Low-Light Face Artifact Removal Comparison
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/Deblurring.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        <br>
        Low-Light Face Deblurring Comparison
      </h2>
    </div>
    <div class="item">
        <!-- Your image here -->
        <img src="static/images/Restoration.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br>
          Low-Light Blind Face Restoration Comparison
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Restoration1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br>
          Real-world Low-Light Face Restoration Comparison
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sfmnet,
  title={Spatial-Frequency Mutual Learning for Low-Light Face Restoration},
  author={Chenyang Wang, Junjun Jiang, Zhiwei Zhong, Kui Jiang, and Xianming Liu},
  year={2024}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
